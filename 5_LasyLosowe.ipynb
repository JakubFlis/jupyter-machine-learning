{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'utils/imports_5.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasy losowe\n",
    "\n",
    "Lasy losowe to klasyfikator nadający się do rozwiązywania problemów zarówno klasyfikacji, jak i regresji. Składa się z zestawu wytrenowanych w losowy sposób drzew decyzyjnych, z których każdy podejmuje niezależnie decyzję. Jako ostateczną decyzję klasyfikatora lasu losowego wybierana jest ta decyzja, która była najliczniejsza spośród decyzji drzew decyzyjnych.\n",
    "\n",
    "Zasadę działania lasów losowych prezentuje poniższa grafika.\n",
    "\n",
    "<img src=\"img/random_forest.png\" alt=\"Naive net\" style=\"height: 350px;\"/>\n",
    "\n",
    "W ramach niniejszego skryptu skupiono się na zadaniu klasyfikacji przez lasy losowe.\n",
    "\n",
    "---\n",
    "\n",
    "### Opis zasady działania\n",
    "\n",
    "Zestaw danych przykładowych `Iris` [[1](https://en.wikipedia.org/wiki/Iris_flower_data_set)] zawiera informacje o wielkości elementów kwiatu irysa i przynależnosć do konkretnego gatunku. Przynależność do konkretnego gatunku na podstawie tych informacji spróbuje przewidzieć wytrenowany w dalszej części tego skryptu klasyfikator lasów decyzyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = np.array([iris.target_names[i] for i in iris.target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relacje wzajemne atrybutów w zbiorze testowym przedstawiono na poniższym zestawie wykresów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kolejnej części następuje podział na dane trenujące i weryfikujące:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[iris.feature_names], iris.target, test_size=0.5, stratify=iris.target, random_state=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator lasów decyzyjnych, podobnie jak inne klasyfikatory bibloiteki `scikit-learn`, trenowany jest za pomocą funkcji `fit()`. \n",
    "\n",
    "* Najważniejszym parametrem tego klasyfikatora jest `n_estimators`. Określa on ile drzew decyzyjnych wejdzie w skład rodziny klasyfikatorów lasu decyzyjnego. \n",
    "\n",
    "* `criterion` określa kryterium wyboru podczas podziału na węzły decyzyjne w procesie trenowania drzewa decyzyjnego. Możliwe wartości to `gini` oraz `entropy`. \n",
    "\n",
    "Po wytrenowaniu klasyfikatora, pod komórką wyświetli się opis powstałego obiektu wraz z wartościami wszystkich parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, criterion='entropy')\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja `predict()` wykorzystuje wytrenowany las do podjęcia decyzji o klasyfikacji. Aby sprawdzić klasyfikację w porównaniu do poprawnych wartości, wykorzystywana jest funkcja `accuracy_score`. Warto zauważyć, że tym razem użyto zbioru `X_test`. Klasyfikator do tej pory nie miał styczności z tymi danymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = rf.predict(X_test)\n",
    "print(f'Średnia poprawność klasyfikacji: {accuracy_score(y_test, predicted):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak można zauważyć, poprawność klasyfikacji jest dość wysoka (ok. 94%).\n",
    "\n",
    "Wszystie drzewa decyzyjne są określone w atrybucie `estimators_` lasu losowego. Można zwizualizować drzewo wchodzące w skład lasu za pomocą klasy `DecisionTreeGraphMaker`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DecisionTreeGraphMaker().draw_graph(rf.estimators_[0], X_train.columns)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macierz pomyłek - confusion matrix\n",
    "\n",
    "Macierz pomyłek [[2](https://en.wikipedia.org/wiki/Confusion_matrix)] to metoda wizualizacji błędu klasyfikacji w celu oceny jej jakości. Każdy z wierszy reprezentuje instancje klasy przewidziane przez klasyfikator, natomiast kolumny reprezentują instancje klasy poprawnej, zapisanej w zbiorze weryfikującym.\n",
    "\n",
    "Na poniższej macierzy pomyłek można zauważyć, że jedynie kilka (dokładnie 5) gatunków `versicolor` zostało sklasyfikowanych jako `virginica`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_test, predicted), columns=iris.target_names, index=iris.target_names)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja i K-krotna walidacja krzyżowa plików ARFF\n",
    "---\n",
    "Poniższa tablica zawiera wykorzystywane w [poprzednich skryptach](1_SieciBayesowskie.ipynb) pliki ARFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arff_paths= ['data/car.arff',     #0\n",
    "            'data/credit.arff',   #1\n",
    "            'data/patient.arff',  #2\n",
    "            'data/weather.arff',  #3\n",
    "            'data/tumor.arff',    #4\n",
    "            'data/zoo.arff']      #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybór pliku ARFF do dalszej analizy odbywa się za pomocą modyfikacji zmiennej `arff_file_index`. Dane zostają załadowane i od razu podzielone na trenujące i weryfikacyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arff_file_index = 0\n",
    "\n",
    "data = load_arff(arff_paths[arff_file_index])\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kolejnym kroku wybrany plik ARFF zostaje wytrenowany w analogiczny sposób do poprzedniego klasyfikatora lasu losowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=10, criterion='entropy')\n",
    "randomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejny punkt zawiera:\n",
    "* Predykcja za pomocą funkcji `predict()`, \n",
    "* tworzenie macierzy pomyłek,\n",
    "* obliczanie średniej poprawności klasyfikacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = randomForest.predict(X_test)\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix(y_test, predicted_values))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "print(f'Średnia poprawność klasyfikacji: {accuracy_score(y_test, predicted_values):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### K-krotna walidacja krzyżowa\n",
    "\n",
    "Podobnie jak w poprzednich skryptach, do dokładniejszego określenia poprawności działania lasów losowych użyta zostanie metoda k-krotnej walidacji krzyżowej. Modyfikując parametr `cv` można operować liczbą podzbiorów wytworzonych z danych wejściowych i jednocześnie liczbę iteracji wykonywanych do obliczenia średniego błedu klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(randomForest, X, y, cv=5)\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
