{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import graphviz\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import arff\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Algorytm K2\n",
    "<img src=\"img/K2.png\" style=\"height: 350px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K2Algorithm(object):\n",
    "    def __init__(self, attributes, test_data, scoring_method, max_number_of_parents):\n",
    "        self.test_data = test_data\n",
    "        self.scoring_method = scoring_method\n",
    "        self.attributes = attributes\n",
    "        self.max_number_of_parents = max_number_of_parents\n",
    "        \n",
    "    def new_find_optimal_net(self):\n",
    "        optimal_net = []\n",
    "        \n",
    "        for i, attribute in enumerate(self.attributes):\n",
    "            parents_of_node_indexes = []\n",
    "            find_more = True\n",
    "        \n",
    "            old_score = self.compute_metric([{'r': attribute['states'], 'name': attribute['name'], 'parents': []}])\n",
    "\n",
    "            while (find_more and len(parents_of_node_indexes) < self.max_number_of_parents):\n",
    "                max_new_parent_score, max_new_parent_index = self.find_node_with_max_score(i, attribute, parents_of_node_indexes)\n",
    "                \n",
    "                if (max_new_parent_score > old_score):\n",
    "                    old_score = max_new_parent_score\n",
    "                    parents_of_node_indexes.append(max_new_parent_index)\n",
    "                else:\n",
    "                    find_more = False\n",
    "                    \n",
    "            optimal_net.append({'r': attribute['states'], 'name': attribute['name'], 'parents': self.convert_array_of_indexes_to_parents(parents_of_node_indexes)})\n",
    "                          \n",
    "        return optimal_net\n",
    "    \n",
    "    def find_node_with_max_score(self, index, attribute, parent_indexes):\n",
    "        current_parents = []\n",
    "        for current_parent_index in parent_indexes:\n",
    "            current_parents.append(self.convert_index_to_parent(current_parent_index))\n",
    "        temp_net = [{'name': attribute['name'], 'r': attribute['states'], 'parents': current_parents}]\n",
    "        \n",
    "        parent_index_with_max_score = -1\n",
    "        max_score = self.compute_metric(temp_net)\n",
    "        \n",
    "        for parent_index in range(0, index):\n",
    "            if parent_index not in parent_indexes:\n",
    "                temp_net_copy = copy.deepcopy(temp_net)\n",
    "                temp_net_copy[0]['parents'].append(self.convert_index_to_parent(parent_index))\n",
    "                parent_candidate_score = self.compute_metric(temp_net_copy)\n",
    "                \n",
    "                if (parent_candidate_score > max_score):\n",
    "                    max_score = parent_candidate_score\n",
    "                    parent_index_with_max_score = parent_index\n",
    "                \n",
    "        return (max_score, parent_index_with_max_score)\n",
    "    \n",
    "    def convert_index_to_parent(self, index):\n",
    "        return {'name': self.attributes[index]['name'], 'q': self.attributes[index]['states']}\n",
    "    \n",
    "    def convert_array_of_indexes_to_parents(self, indexes):\n",
    "        parents = []\n",
    "        for index in indexes:\n",
    "            parents.append(self.convert_index_to_parent(index))\n",
    "        return parents\n",
    "    \n",
    "    def compute_metric(self, net):\n",
    "        if self.scoring_method == 'aic':\n",
    "            return AICMetric().compute_aic_metric(net, self.test_data)\n",
    "        elif self.scoring_method == 'mdl':\n",
    "            return MDLMetric().compute_mdl_metric(net, self.test_data)\n",
    "        elif self.scoring_method == 'bayes':\n",
    "            return BayesianMetric().compute_bayesian_metric(net, self.test_data)\n",
    "        \n",
    "        raise ValueError(self.scoring_method + \" is not a valid scoring method!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Metryka AIC \n",
    "<img src=\"img/qaic.png\">\n",
    "<img src=\"img/k.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AICMetric(object):\n",
    "    def compute_aic_metric(self, Bs, D):\n",
    "        return EntropyMetric(Bs, D).compute_entropy_metric() + self.compute_k_factor(Bs)\n",
    "    \n",
    "    def compute_k_factor(self, network):\n",
    "        k_factor = 0\n",
    "        for node in network:\n",
    "            k_factor += (len(node['r']) - 1) * self.count_number_of_parent_states(node)\n",
    "        return k_factor\n",
    "    \n",
    "    def count_number_of_parent_states(self, node):\n",
    "        counter = 0\n",
    "        for parent in node['parents']:\n",
    "            counter += len(parent['q'])\n",
    "        return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Metryka MDL (Minimum Description Length)\n",
    "<img src=\"img/mdl.png\" style=\"height: 60px\"> <br/>\n",
    "<img src=\"img/k.png\" style=\"height: 60px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDLMetric(object):\n",
    "    def compute_mdl_metric(self, network, test_data):\n",
    "        return EntropyMetric(network, test_data).compute_entropy_metric() + (self.compute_k_factor(network) / 2) * math.log10(len(test_data))\n",
    "    \n",
    "    def compute_k_factor(self, network):\n",
    "        k_factor = 0\n",
    "        for node in network:\n",
    "             k_factor += (len(node['r']) - 1) * self.count_number_of_parent_states(node)\n",
    "        return k_factor\n",
    "    \n",
    "    def count_number_of_parent_states(self, node):\n",
    "        counter = 0\n",
    "        for parent in node['parents']:\n",
    "            counter += len(parent['q'])\n",
    "        return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Entropia\n",
    "<img src=\"img/h.png\" style=\"height: 80px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyMetric(object):\n",
    "    \"\"\"Entropy metric H(Bs, D) module (Bs - Bayes net, D - test data set)\"\"\"\n",
    "    def __init__(self, network, test_data):\n",
    "        self.network = network\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def compute_entropy_metric(self):\n",
    "        result = 0\n",
    "        \n",
    "        for node in self.network:\n",
    "            if not node['parents']: # Brak rodzica\n",
    "                result += self.compute_metric_for_node_without_parent(node)\n",
    "                continue\n",
    "                \n",
    "            for node_state in node['r']:\n",
    "                for parent in node['parents']:\n",
    "                    for parent_state in parent['q']:\n",
    "                        N_i_j = self.compute_occurences_for_all_node_states(node, (parent['name'], parent_state))\n",
    "                        N_i_j_k = self.count_occurences((node['name'], node_state), (parent['name'], parent_state))\n",
    "                        if (N_i_j_k != 0 and N_i_j != 0):\n",
    "                            result += self.compute_metric_component(N_i_j, N_i_j_k)\n",
    "                    \n",
    "        return -1 * len(self.test_data) * result\n",
    "    \n",
    "    def compute_metric_for_node_without_parent(self, node):  \n",
    "        N_i_j = len(self.test_data)\n",
    "        N_i_j_k = self.compute_occurences_for_all_node_states_without_parent(node)\n",
    "        \n",
    "        return self.compute_metric_component(N_i_j, N_i_j_k)\n",
    "    \n",
    "    def compute_occurences_for_all_node_states(self, node, parent):\n",
    "        result = 0\n",
    "        for state in node['r']:\n",
    "            result += self.count_occurences((node['name'], state), parent)\n",
    "        return result\n",
    "    \n",
    "    def compute_occurences_for_all_node_states_without_parent(self, node):\n",
    "        result = 0\n",
    "        for state in node['r']:\n",
    "            result += self.count_single_occurences(node['name'], state)\n",
    "        return result\n",
    "    \n",
    "    def count_occurences(self, node, parent):\n",
    "        counter = 0\n",
    "        for data in self.test_data:\n",
    "            if data[node[0]] == node[1] and data[parent[0]] == parent[1]:\n",
    "                counter += 1 \n",
    "        return counter\n",
    "    \n",
    "    def count_single_occurences(self, name, state):\n",
    "        counter = 0\n",
    "        for data in self.test_data:\n",
    "            if data[name] == state:\n",
    "                counter += 1 \n",
    "        return counter\n",
    "     \n",
    "    def compute_metric_component(self, N_i_j, N_i_j_k):\n",
    "        return (N_i_j_k / len(self.test_data)) * math.log10(N_i_j_k / N_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### ≈Åadowanie pliku ARFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/weather.arff') as fh:\n",
    "    data = arff.load(fh)\n",
    "    \n",
    "    attributes = []\n",
    "    for i, p in enumerate(data['attributes']):\n",
    "        attributes.append({'name': p[0], 'states': p[1]})\n",
    "    \n",
    "    sample_data = []\n",
    "    for i, p in enumerate(data['data']):\n",
    "        temp_dict = {}\n",
    "        for j, d in enumerate(p):\n",
    "            temp_dict.update({attributes[j]['name']: d})\n",
    "        sample_data.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Wyb√≥r argumentu - klasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    index_of_class_attribute = 4\n",
    "    print(\"Class argument: \")\n",
    "    pp.pprint(attributes[index_of_class_attribute])\n",
    "    \n",
    "    final_attributes = []\n",
    "    final_attributes.append(attributes[index_of_class_attribute])\n",
    "    \n",
    "    for i, p in enumerate(attributes):\n",
    "        if i != index_of_class_attribute:\n",
    "            final_attributes.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### G≈Ç√≥wne wywo≈Çanie algorytmu i rysowanie grafu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metody oceny sieci: 'aic' lub 'mdl'\n",
    "bayesian_network = K2Algorithm(final_attributes, sample_data, 'mdl', 1).new_find_optimal_net()\n",
    "\n",
    "graph = graphviz.Digraph('generated graph')        \n",
    "for node in bayesian_network:\n",
    "    if not node['parents']:\n",
    "        graph.node(node['name'] , label = node['name'])\n",
    "    else:\n",
    "        for parent in node['parents']:\n",
    "            graph.edge(parent['name'], node['name'])          \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Klasyfikacja przy dowolnych podanych warunkach\n",
    "<img src=\"img/classify.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class From(object):\n",
    "    def __init__(self, bayesian_network, test_data):\n",
    "        self.bayesian_network = bayesian_network\n",
    "        self.conditionals = []\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def given(self, name, value):\n",
    "        self.conditionals.append({\"name\": name, \"value\": value})\n",
    "        return self\n",
    "    \n",
    "    def classify(self, class_attribute_name):\n",
    "        final_result = []\n",
    "        for class_state in self.find_class_attribute_states(class_attribute_name):\n",
    "            result = 1\n",
    "            temp_conditionals = copy.deepcopy(self.conditionals)\n",
    "            temp_conditionals.append({\"name\": class_attribute_name, \"value\": class_state})\n",
    "            \n",
    "            for node in self.bayesian_network:\n",
    "                tuples = []\n",
    "                tuples.append((node[\"name\"], self.get_conditional_value(node['name'], temp_conditionals), True))\n",
    "                    \n",
    "                for parent in node['parents']:    \n",
    "                    tuples.append((parent['name'], self.get_conditional_value(parent['name'], temp_conditionals), False))\n",
    "                    \n",
    "                result *= self.compute_probability(tuples)\n",
    "            \n",
    "            final_result.append({\"state\": class_state, \"value\": result})  \n",
    "                \n",
    "        return self.normalize_probabilities_sum(final_result)\n",
    "    \n",
    "    def normalize_probabilities_sum(self, result_table):\n",
    "        probabilities_sum = self.compute_probabilities_sum(result_table)\n",
    "        for result in result_table:\n",
    "            result['value'] = (result['value'] / probabilities_sum) * 100.0\n",
    "        return result_table\n",
    "    \n",
    "    def compute_probabilities_sum(self, result_table):\n",
    "        probabilities_sum = 0\n",
    "        for result in result_table:\n",
    "            probabilities_sum += result['value']\n",
    "        return probabilities_sum\n",
    "            \n",
    "    def get_conditional_value(self, name, conditionals):\n",
    "        for conditional in conditionals:\n",
    "            if conditional[\"name\"] == name:\n",
    "                return conditional[\"value\"]\n",
    "        raise ValueError(\"There's no \" + name + \" conditional in conditionals\")\n",
    "    \n",
    "    def find_class_attribute_states(self, class_attribute_name):\n",
    "        for node in self.bayesian_network:\n",
    "            if (node['name'] == class_attribute_name):\n",
    "                return node['r']\n",
    "            \n",
    "        raise ValueError(class_attribute_name + \" -> No class attribute state error\")\n",
    "    \n",
    "    def compute_probability(self, tuples):\n",
    "        all_conditions_counter = self.count_occurences_of_fullfilled_conditions(tuples)\n",
    "        \n",
    "        if len(tuples) == 0: \n",
    "            return all_conditions_counter / len(self.test_data)\n",
    "\n",
    "        self.delete_parent_from_tuples(tuples)\n",
    "        \n",
    "        parent_conditions_counter = self.count_occurences_of_fullfilled_conditions(tuples)\n",
    "        \n",
    "        if all_conditions_counter == 0 or parent_conditions_counter == 0:\n",
    "            return 1 / self.count_number_of_states(tuples)\n",
    "\n",
    "        return all_conditions_counter / parent_conditions_counter\n",
    "    \n",
    "    def count_occurences_of_fullfilled_conditions(self, tuples):\n",
    "        counter = 0\n",
    "        for test_data_line in self.test_data:\n",
    "            if (self.does_test_line_fullfill_conditions(tuples, test_data_line)):\n",
    "                counter += 1\n",
    "        return counter\n",
    "    \n",
    "    def does_test_line_fullfill_conditions(self, tuples, test_data_line):\n",
    "        for condition_tuple in tuples:\n",
    "            if test_data_line[condition_tuple[0]] != condition_tuple[1]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def count_number_of_states(self, tuples):\n",
    "        result = 0\n",
    "        for single_tuple in tuples:\n",
    "            for node in self.bayesian_network:\n",
    "                if node['name'] == single_tuple[0]:\n",
    "                    result += len(node['r'])\n",
    "        return result\n",
    "    \n",
    "    def delete_parent_from_tuples(self, tuples):\n",
    "        for i, single_tuple in enumerate(tuples):\n",
    "            if single_tuple[2]:\n",
    "                del tuples[i]\n",
    "        return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'hot').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'hot').given('humidity', 'high').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'hot').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'mild').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'mild').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'mild').given('humidity', 'high').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'hot').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'high').given('windy', 'TRUE').classify('play'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
