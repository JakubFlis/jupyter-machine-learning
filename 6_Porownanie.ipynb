{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets, model_selection\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score, recall_score, precision_score\n",
    "from sklearn.metrics import mean_absolute_error, average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, log_loss, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "%run 'utils/imports_1.ipynb'\n",
    "%run 'utils/arff.ipynb'\n",
    "%run 'utils/arffconverter.ipynb'\n",
    "%run 'utils/arffcrossvalidation.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Zależność wielkości zbioru testowego od poprawności klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ComputeForArff(object):\n",
    "    def __init__(self, classifier, arff_path, splits):\n",
    "        self.classifier = classifier\n",
    "        self.arff_path = arff_path\n",
    "        self.splits = splits\n",
    "        self.seed = 7\n",
    "    \n",
    "    def compute_result(self):\n",
    "        data = load_arff(self.arff_path)\n",
    "        \n",
    "        kfold = model_selection.KFold(n_splits=self.splits, random_state=self.seed)\n",
    "        return cross_val_score(self.classifier, data.data, data.target, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeBayesianNetworkStats(object):\n",
    "    def __init__(self, classifier, arff_array):\n",
    "        self.classifier = classifier\n",
    "        self.arff_array = arff_array\n",
    "        \n",
    "    def compute_stats_dataframe(self):\n",
    "        bn_data = dict()\n",
    "        for i, path in enumerate(self.arff_array):\n",
    "            print(i)\n",
    "            bn_values = self.compute_stats(path)\n",
    "            bn_data[labels[::-1][i]] = bn_values\n",
    "        \n",
    "        return pd.DataFrame(data=bn_data, index=[\"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])\n",
    "        \n",
    "    def compute_stats(self, arff_path):\n",
    "        attributes, a, b = ARFFLoader(arff_path).load_attributes_and_samples(8, 100)\n",
    "        y, predicted = KFoldCrossValidation(arff_path, 8).predict(self.classifier)\n",
    "\n",
    "        final_predicted = []\n",
    "        for pred in predicted:\n",
    "            for i, t in enumerate(attributes[0]['states']):\n",
    "                if t == pred:\n",
    "                    final_predicted.append(i)\n",
    "                    continue\n",
    "\n",
    "        final_y = []\n",
    "        for pred in y:\n",
    "            for i, t in enumerate(attributes[0]['states']):\n",
    "                if t == pred:\n",
    "                    final_y.append(i)\n",
    "                    continue      \n",
    "\n",
    "        PRECISION = precision_score(final_y, final_predicted, average='weighted')\n",
    "        RECALL = recall_score(final_y, final_predicted, average='weighted')\n",
    "        F1 = f1_score(final_y, final_predicted, average='weighted')\n",
    "        MAE = mean_absolute_error(final_y, final_predicted)\n",
    "        MSE = mean_squared_error(final_y, final_predicted)\n",
    "        CKS = cohen_kappa_score(final_y, final_predicted)\n",
    "        \n",
    "        return [PRECISION, RECALL, F1, CKS, MAE, MSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeStatisticsForArff(object):\n",
    "    def __init__(self, classifier, arff_path):\n",
    "        self.classifier = classifier\n",
    "        self.arff_path = arff_path\n",
    "    \n",
    "    def compute_result(self):\n",
    "        data = load_arff(self.arff_path)\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123456)\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        predicted_values = self.classifier.predict(X_test)\n",
    "        \n",
    "        PRECISION = precision_score(y_test, predicted_values, average='weighted')\n",
    "        RECALL = recall_score(y_test, predicted_values, average='weighted')\n",
    "        F1 = f1_score(y_test, predicted_values, average='weighted')\n",
    "        CKS = cohen_kappa_score(y_test, predicted_values)\n",
    "        MAE = mean_absolute_error(y_test, predicted_values)\n",
    "        MSE = mean_squared_error(y_test, predicted_values)\n",
    "        \n",
    "        return [PRECISION, RECALL, F1, CKS, MAE, MSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nursery_paths = ['data/comparison/nursery_200.arff',\n",
    "                'data/comparison/nursery_400.arff',\n",
    "                'data/comparison/nursery_800.arff', \n",
    "                'data/comparison/nursery_1000.arff',\n",
    "                'data/comparison/nursery_2000.arff',\n",
    "                'data/comparison/nursery_4000.arff',\n",
    "                'data/comparison/nursery_8000.arff',\n",
    "                'data/comparison/nursery_12960.arff']\n",
    "\n",
    "best_arff = 7\n",
    "data = load_arff(nursery_paths[best_arff])\n",
    "\n",
    "labels = [200, 400, 800, 1000, 2000, 4000, 8000, 12960]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.light_palette((210, 90, 60), input=\"husl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_df = pd.DataFrame()\n",
    "linear_data = dict()\n",
    "rbf_data = dict()\n",
    "   \n",
    "for i, nursery in enumerate(nursery_paths): \n",
    "    value = ComputeForArff(SVC(kernel='linear', C=50), nursery, 10).compute_result()\n",
    "    linear_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['kernel'] = \"linear\"\n",
    "    SVM_df = SVM_df.append(df_temp)\n",
    "\n",
    "for i, nursery in enumerate(nursery_paths):\n",
    "    value = ComputeForArff(SVC(kernel='rbf', C=50), nursery, 10).compute_result()\n",
    "    rbf_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['kernel'] = \"rbf\"\n",
    "    SVM_df = SVM_df.append(df_temp)\n",
    "\n",
    "for i, path in enumerate(nursery_paths):\n",
    "    linear_values = ComputeStatisticsForArff(SVC(kernel='linear', C=50), path).compute_result()\n",
    "    linear_data[labels[i]] += linear_values\n",
    "    \n",
    "    rbf_values = ComputeStatisticsForArff(SVC(kernel='rbf', C=50), path).compute_result()\n",
    "    rbf_data[labels[i]] += rbf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kernel_df = pd.DataFrame(data=linear_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])\n",
    "rbf_kernel_df = pd.DataFrame(data=rbf_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 9)})\n",
    "plt.ylim(0.58, 1.01)\n",
    "\n",
    "sns.boxplot(x=\"size\", y=\"value\", hue=\"kernel\", data=SVM_df, palette=sns.light_palette(\"green\")).set_title(\"SVM, kernel = {linear, rbf}, 10-fold cross validation, nursery.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_kernel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kernel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN_df = pd.DataFrame()\n",
    "k_5_data = dict()\n",
    "k_25_data = dict()\n",
    "\n",
    "for i, nursery in enumerate(nursery_paths):\n",
    "    value = ComputeForArff(KNeighborsClassifier(5, weights='distance'), nursery, 10).compute_result()\n",
    "    k_5_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['knn'] = \"5\"\n",
    "    KNN_df = KNN_df.append(df_temp)\n",
    "\n",
    "for i, nursery in enumerate(nursery_paths): \n",
    "    value = ComputeForArff(KNeighborsClassifier(25, weights='distance'), nursery, 10).compute_result()\n",
    "    k_25_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['knn'] = \"25\"\n",
    "    KNN_df = KNN_df.append(df_temp)\n",
    "\n",
    "for i, path in enumerate(nursery_paths):\n",
    "    k_5_values = ComputeStatisticsForArff(KNeighborsClassifier(5, weights='distance'), path).compute_result()\n",
    "    k_5_data[labels[i]] += k_5_values\n",
    "    \n",
    "    k_25_values = ComputeStatisticsForArff(KNeighborsClassifier(25, weights='distance'), path).compute_result()\n",
    "    k_25_data[labels[i]] += k_25_values\n",
    "    \n",
    "k_5_df = pd.DataFrame(data=k_5_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])\n",
    "k_25_df = pd.DataFrame(data=k_25_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 9)})\n",
    "plt.ylim(0.58, 1.01)\n",
    "sns.boxplot(x=\"size\", y=\"value\", hue=\"knn\", data=KNN_df, palette=sns.light_palette(\"green\")).set_title('K-NN, K={5, 25}, 10-fold cross validation, nursery.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_25_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Lasy losowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LL_df = pd.DataFrame()\n",
    "est_50_data = dict()\n",
    "est_100_data = dict()\n",
    "   \n",
    "for i, nursery in enumerate(nursery_paths):\n",
    "    value = ComputeForArff(RandomForestClassifier(n_estimators=50, criterion='entropy'), nursery, 10).compute_result()\n",
    "    est_50_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['estimators'] = \"50\"\n",
    "    LL_df = LL_df.append(df_temp)\n",
    "\n",
    "for i, nursery in enumerate(nursery_paths):\n",
    "    value = ComputeForArff(RandomForestClassifier(n_estimators=100, criterion='entropy'), nursery, 10).compute_result()\n",
    "    est_100_data[labels[i]] = [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[i]\n",
    "    df_temp['estimators'] = \"100\"\n",
    "    LL_df = LL_df.append(df_temp)\n",
    "    \n",
    "for i, path in enumerate(nursery_paths):\n",
    "    est_50_values = ComputeStatisticsForArff(RandomForestClassifier(n_estimators=5, criterion='entropy'), path).compute_result()\n",
    "    est_50_data[labels[i]] += est_50_values\n",
    "    \n",
    "    est_100_values = ComputeStatisticsForArff(RandomForestClassifier(n_estimators=50, criterion='entropy'), path).compute_result()\n",
    "    est_100_data[labels[i]] += est_100_values\n",
    "    \n",
    "est_50_df = pd.DataFrame(data=est_50_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])\n",
    "est_100_df = pd.DataFrame(data=est_100_data, index=[\"Mean\", \"Std\", \"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 9)})\n",
    "plt.ylim(0.58, 1.01)\n",
    "labels = labels[::-1]\n",
    "sns.set_palette(sns.light_palette(\"green\"))\n",
    "sns.boxplot(x=\"size\", y=\"value\", hue=\"estimators\", data=LL_df).set_title('Random forests, no. of estimators = {50, 100}, 10-fold cross validation, nursery.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_50_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_100_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sieci bayesowskie - porównanie algorytmów w zależności od data setu\n",
    "\n",
    "# ! Wywołanie poniższego skryptu jest czasochłonne - w zależności od komputera może potrwać od 3 do 5 godzin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bn_splits = 10\n",
    "\n",
    "BN_df = pd.DataFrame()\n",
    "\n",
    "total = len(nursery_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BN_K2_df = pd.DataFrame()\n",
    "\n",
    "K2_stats_dict_temp = dict()\n",
    "\n",
    "for i, path in enumerate(nursery_paths):\n",
    "    print(i + 1, \"of\", total)\n",
    "    value = KFoldCrossValidation(path, 8).perform_k_fold_cross_validation(bn_splits, K2Algorithm(score_method='aic', number_of_parents=3))\n",
    "    K2_stats_dict_temp[labels[::-1][i]] =  [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[::-1][i]\n",
    "    df_temp['name'] = \"K2\"\n",
    "    BN_K2_df = BN_K2_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BN_TAN_df = pd.DataFrame()\n",
    "\n",
    "TAN_stats_dict_temp = dict()\n",
    "\n",
    "for i, path in enumerate(nursery_paths):\n",
    "    print(i + 1, \"of\", total)\n",
    "    value = KFoldCrossValidation(path, 8).perform_k_fold_cross_validation(bn_splits, TANAlgorithm())\n",
    "    TAN_stats_dict_temp[labels[::-1][i]] =  [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[::-1][i]\n",
    "    df_temp['name'] = \"TAN\"\n",
    "    BN_TAN_df = BN_TAN_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BN_TABU_df = pd.DataFrame()\n",
    "\n",
    "TABU_stats_dict_temp = dict()\n",
    "\n",
    "for i, path in enumerate(nursery_paths):\n",
    "    print(i + 1, \"of\", total)\n",
    "    value = KFoldCrossValidation(path, 8).perform_k_fold_cross_validation(bn_splits, TabuSearch(score_method='aic', number_of_parents=2, number_of_iterations=10, tabu_length=5))\n",
    "    TABU_stats_dict_temp[labels[::-1][i]] =  [value.mean(), value.std()]\n",
    "    df_temp = pd.DataFrame({\"value\": value})\n",
    "    df_temp['size'] = labels[::-1][i]\n",
    "    df_temp['name'] = \"TABU\"\n",
    "    BN_TABU_df = BN_TABU_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN_df = pd.DataFrame()\n",
    "BN_df = BN_df.append(BN_TAN_df)\n",
    "BN_df = BN_df.append(BN_K2_df)\n",
    "BN_df = BN_df.append(BN_TABU_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 9)})\n",
    "plt.ylim(0.48, 1.01)\n",
    "sns.set_palette(sns.light_palette(\"green\"))\n",
    "sns.boxplot(x=\"size\", y=\"value\", hue=\"name\", data=BN_df).set_title('Bayesian networks, 10-fold cross validation, TAN/TABU/K2, nursery.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K2_stats_df = ComputeBayesianNetworkStats(K2Algorithm(score_method='aic', number_of_parents=3), nursery_paths).compute_stats_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAN_stats_df = ComputeBayesianNetworkStats(TANAlgorithm(), nursery_paths).compute_stats_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABU_stats_df = ComputeBayesianNetworkStats(TabuSearch(score_method='aic', number_of_parents=2, number_of_iterations=10, tabu_length=5), nursery_paths).compute_stats_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2_stats_df_temp = pd.DataFrame(data=K2_stats_dict_temp, index=[\"mean\", \"std\"])\n",
    "pd.concat([K2_stats_df, K2_stats_df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAN_stats_df_temp = pd.DataFrame(data=TAN_stats_dict_temp, index=[\"mean\", \"std\"])\n",
    "pd.concat([TAN_stats_df, TAN_stats_df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABU_stats_df_temp = pd.DataFrame(data=TABU_stats_dict_temp, index=[\"mean\", \"std\"])\n",
    "pd.concat([TABU_stats_df, TABU_stats_df_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Porównanie algorytmów - wykres świecowy\n",
    "\n",
    "* SVM - kernel=rbf, bo wyszło najkorzystniej,\n",
    "* BN - TAN, bo wyszedł najkorzystniej,\n",
    "* KNN - k=5, bo wyszło najkorzystniej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "splits = 10\n",
    "seed = 7\n",
    "path = nursery_paths[best_arff]\n",
    "classifier_names = ['SVM', 'KNN', 'LL']\n",
    "\n",
    "names = []\n",
    "results = []\n",
    "models = []\n",
    "models.append(('SVM', SVC(kernel='rbf', C=50)))\n",
    "models.append(('KNN', KNeighborsClassifier(25, weights='distance')))\n",
    "models.append(('LL', RandomForestClassifier(n_estimators=100, criterion='entropy')))\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "temp_summary = dict()\n",
    "    \n",
    "for i, (name, model) in enumerate(models):\n",
    "    kfold = model_selection.KFold(n_splits=splits, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold)\n",
    "    temp_summary[classifier_names[i]] = [cv_results.mean(), cv_results.std()]\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "bn_value = KFoldCrossValidation(nursery_paths[best_arff], 8).perform_k_fold_cross_validation(10, TANAlgorithm())\n",
    "results.append(bn_value)    \n",
    "names.append(\"BN TAN\")    \n",
    "temp_summary[\"BN\"] = [bn_value.mean(), bn_value.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_SVM = pd.DataFrame({\"value\": results[0]})\n",
    "pd_SVM['name'] = \"SVM\"\n",
    "\n",
    "pd_KNN = pd.DataFrame({\"value\": results[1]})\n",
    "pd_KNN['name'] = \"KNN\"\n",
    "\n",
    "pd_LL = pd.DataFrame({\"value\": results[2]})\n",
    "pd_LL['name'] = \"LL\"\n",
    "\n",
    "pd_TAN = pd.DataFrame({\"value\": results[3]})\n",
    "pd_TAN['name'] = \"BN TAN\"\n",
    "\n",
    "COMP_df = pd.DataFrame()\n",
    "COMP_df = COMP_df.append(pd_SVM)\n",
    "COMP_df = COMP_df.append(pd_KNN)\n",
    "COMP_df = COMP_df.append(pd_LL)\n",
    "COMP_df = COMP_df.append(pd_TAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 11)})\n",
    "sns.set_palette(sns.light_palette(\"green\"))\n",
    "sns.boxplot(x=\"name\", y=\"value\", data=COMP_df, order=['SVM', 'LL', 'KNN', 'BN TAN']).set_title(\"SVM/KNN/LL/BN TAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_SVM = ComputeStatisticsForArff(SVC(), path).compute_result()\n",
    "est_KNN = ComputeStatisticsForArff(KNeighborsClassifier(), path).compute_result()\n",
    "est_LL = ComputeStatisticsForArff(RandomForestClassifier(n_estimators=10, criterion='entropy'), path).compute_result()\n",
    "est_BN = ComputeBayesianNetworkStats(TANAlgorithm(), []).compute_stats(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_best_stat = est_SVM + temp_summary['SVM']\n",
    "KNN_best_stat = est_KNN + temp_summary['KNN']\n",
    "LL_best_stat = est_LL + temp_summary['LL']\n",
    "BN_best_stat = est_BN + temp_summary['BN']\n",
    "\n",
    "d = {'SVM': SVM_best_stat, 'KNN': KNN_best_stat, 'LL': LL_best_stat, 'BN TAN': BN_best_stat}\n",
    "df = pd.DataFrame(data=d, index=[\"Precision\", \"Recall\", \"F1\", \"CKS\", \"MAE\", \"MSE\", \"Mean\", \"Std\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozkład parametrów w zbiorze danych testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckClassNumbers(object):\n",
    "    def plot_stats(self, path):\n",
    "        loading_data = load_arff(path)\n",
    "        result = [0, 0, 0, 0]\n",
    "        for target in loading_data.target:\n",
    "            result[int(target)] += 1\n",
    "        \n",
    "        print(result)\n",
    "            \n",
    "        sns.set(rc={'figure.figsize':(8, 6)})\n",
    "        sns.barplot(loading_data.target_names, result, palette=\"BuGn_d\")\n",
    "    \n",
    "    def show_stat_table(self):\n",
    "        final_result = dict()\n",
    "        target_names = []\n",
    "        for i, path in enumerate(nursery_paths):\n",
    "            loading_data = load_arff(path)\n",
    "            if target_names == []:\n",
    "                target_names = loading_data.target_names\n",
    "                \n",
    "            result = [0, 0, 0, 0]\n",
    "            for target in loading_data.target:\n",
    "                result[int(target)] += 1\n",
    "            \n",
    "            final_result[labels[i]] = result\n",
    "        return pd.DataFrame.from_dict(final_result, orient='index')\n",
    "        \n",
    "CheckClassNumbers().plot_stats('data/comparison_new/nursery_100.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_200.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_400.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_800.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_1000.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_2000.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_4000.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_8000.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckClassNumbers().plot_stats('data/comparison/nursery_12960.arff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
