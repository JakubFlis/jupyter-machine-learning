{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import math\n",
    "import graphviz\n",
    "import copy\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm TAN - Tree Augumented Naive Bayes  \n",
    "<img src=\"img/TAN-algo.png\" style=\"height: 200px\">\n",
    "<img src=\"img/TAN-prob.png\" style=\"height: 100px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TANAlgorithm(object):\n",
    "    def __init__(self, attributes, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def find_net(self):\n",
    "        computed_net = self.construct_basic_naive_net()\n",
    "        weights, connections = self.compute_all_weights()\n",
    "        \n",
    "        spanning_tree = minimum_spanning_tree(csr_matrix(weights)).toarray().astype(int)\n",
    "        \n",
    "        return self.update_computed_net_with_spanning_tree(spanning_tree, computed_net)\n",
    "    \n",
    "    def update_computed_net_with_spanning_tree(self, spanning_tree, computed_net):\n",
    "        for i, row in enumerate(spanning_tree):\n",
    "            for j, cell in enumerate(row):\n",
    "                if cell != 0:\n",
    "                    start = self.attributes[i + 1]['name']\n",
    "                    end = self.attributes[j + 1]['name']   \n",
    "                    computed_net = self.update_net_with_new_connection(computed_net, start, end)\n",
    "        return computed_net\n",
    "        \n",
    "    \n",
    "    def update_net_with_new_connection(self, net, new_parent_name, node_name):\n",
    "        for node in net:\n",
    "            if node['name'] == node_name:\n",
    "                node['parents'].append({'name': new_parent_name, 'q': self.find_node_states(new_parent_name)})\n",
    "        return net\n",
    "    \n",
    "    def construct_basic_naive_net(self):\n",
    "        computed_net = []\n",
    "        class_attribute = self.attributes[0]\n",
    "        \n",
    "        # Konstruowanie bazowej naiwnej sieci\n",
    "        for i, attribute in enumerate(self.attributes):\n",
    "            # Algorytm zakłada, ze pierwszy element w 'attributes' to klasa\n",
    "            if (i == 0): \n",
    "                computed_net.append({'name': attribute['name'], 'r': attribute['states'], 'parents': []})\n",
    "                continue\n",
    "                \n",
    "            computed_net.append({'name': attribute['name'], 'r': attribute['states'], 'parents': [{'name': class_attribute['name'], 'q': class_attribute['states']}]})\n",
    "        \n",
    "        return computed_net\n",
    "    \n",
    "    def compute_all_weights(self):\n",
    "        class_attribute = self.attributes[0]\n",
    "        connections = []\n",
    "        \n",
    "        size = len(self.attributes) - 1\n",
    "        weights = np.zeros((size, size))\n",
    "            \n",
    "        for attribute_index in range(1, len(self.attributes)):\n",
    "            for second_attribute_index in range(attribute_index + 1, len(self.attributes)):\n",
    "                first_attribute = self.attributes[attribute_index]\n",
    "                second_attribute = self.attributes[second_attribute_index]\n",
    "\n",
    "                weight = self.compute_weight(first_attribute, second_attribute, class_attribute) * 100\n",
    "                weights[attribute_index - 1, second_attribute_index - 1] = weight\n",
    "                \n",
    "                connections.append({'start': first_attribute['name'], 'end': second_attribute['name'], 'weight': weight})\n",
    "        \n",
    "        return (weights, connections)\n",
    "    \n",
    "    def find_node_states(self, node_name):\n",
    "        for attribute in self.attributes:\n",
    "            if attribute['name'] == node_name:\n",
    "                return attribute['states']\n",
    "        raise ValueError(\"No such node: \" + node_name)\n",
    "    \n",
    "    def compute_weight(self, first_argument, second_argument, class_argument):\n",
    "        result = 0\n",
    "        \n",
    "        class_name = class_argument['name']\n",
    "        first_name = first_argument['name']\n",
    "        second_name = second_argument['name']\n",
    "        first_argument_states = first_argument['states']\n",
    "        second_argument_states = second_argument['states']\n",
    "        class_argument_states = class_argument['states']\n",
    "        \n",
    "        for first_state in first_argument_states:\n",
    "            for second_state in second_argument_states:\n",
    "                for class_state in class_argument_states:\n",
    "                    p_c = self.compute_probability(class_name, class_state)\n",
    "                    p_x1_given_c = self.compute_conditional_probability(first_name, first_state, class_name, class_state)\n",
    "                    p_x2_given_c = self.compute_conditional_probability(second_name, second_state, class_name, class_state)\n",
    "                    p_x1_x2_given_c = self.compute_double_conditional_probability((first_name, first_state), (second_name, second_state), (class_name, class_state))\n",
    "                    p_c_x1_x2 = p_c * p_x1_given_c * p_x2_given_c\n",
    "                    \n",
    "                    result += p_c_x1_x2 * math.log10(float(p_x1_x2_given_c) / (p_x1_given_c * p_x2_given_c))\n",
    "     \n",
    "        return result\n",
    "    \n",
    "    def compute_probability(self, argument, argument_state):\n",
    "        #print(\"P(\" + argument + \" = \" + argument_state + \")\")\n",
    "        #i.e. P(play = yes)\n",
    "        number_of_occurences = self.count_number_of_occurences_in_test_data(argument, argument_state)\n",
    "        return number_of_occurences / len(self.test_data)\n",
    "    \n",
    "    def compute_conditional_probability(self, argument, argument_state, condition, condition_state):\n",
    "        #print(\"P(\" + argument + \" = \" + argument_state + \" | \" + condition + \" = \" + condition_state + \")\")\n",
    "        #i.e. P(outlook = sunny | play = yes)\n",
    "        number_of_join_occurences = self.count_double_number_of_occurences_in_test_data((argument, argument_state), (condition, condition_state))\n",
    "        number_of_condition_occurences = self.count_number_of_occurences_in_test_data(condition, condition_state)\n",
    "        \n",
    "        if (number_of_join_occurences == 0 or number_of_condition_occurences == 0):\n",
    "            return 1 / len(self.attributes[0]['states'])\n",
    "            \n",
    "        return number_of_join_occurences / number_of_condition_occurences\n",
    "    \n",
    "    def compute_double_conditional_probability(self, first_argument, second_argument, condition):\n",
    "        #print(\"P(\" + first_argument[0] + \" = \" + first_argument[1] + \", \" + second_argument[0] + \" = \" + second_argument[1] + \" | \" + condition[0] + \" = \" + condition[1] + \")\")\n",
    "        #i.e. P(outlook = sunny, windy = TRUE | play = yes)\n",
    "        number_of_join_occurences = self.count_triple_number_of_occurences_in_test_data(first_argument, second_argument, condition)\n",
    "        number_of_condition_occurences = self.count_number_of_occurences_in_test_data(condition[0], condition[1])\n",
    "        \n",
    "        if (number_of_join_occurences == 0 or number_of_condition_occurences == 0):\n",
    "            return 1 / len(self.attributes[0]['states'])\n",
    "        \n",
    "        return number_of_join_occurences / number_of_condition_occurences\n",
    "    \n",
    "    def count_number_of_occurences_in_test_data(self, name, state):\n",
    "        count = 0\n",
    "        for sample in self.test_data:\n",
    "            if (sample[name] == state):\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def count_double_number_of_occurences_in_test_data(self, first, second):\n",
    "        count = 0\n",
    "        for sample in self.test_data:\n",
    "            if (sample[first[0]] == first[1] and sample[second[0]] == second[1]):\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def count_triple_number_of_occurences_in_test_data(self, first, second, third):\n",
    "        count = 0\n",
    "        for sample in self.test_data:\n",
    "            if (sample[first[0]] == first[1] and sample[second[0]] == second[1] and sample[third[0]] == third[1]):\n",
    "                count += 1  \n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Ładowanie pliku ARFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/weather.arff') as fh:\n",
    "    data = arff.load(fh)\n",
    "    \n",
    "    attributes = []\n",
    "    for i, p in enumerate(data['attributes']):\n",
    "        attributes.append({'name': p[0], 'states': p[1]})\n",
    "    \n",
    "    sample_data = []\n",
    "    for i, p in enumerate(data['data']):\n",
    "        temp_dict = {}\n",
    "        for j, d in enumerate(p):\n",
    "            temp_dict.update({attributes[j]['name']: d})\n",
    "        sample_data.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### Wybór argumentu - klasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    index_of_class_attribute = 4\n",
    "    print(\"Class argument: \")\n",
    "    pp.pprint(attributes[index_of_class_attribute])\n",
    "    \n",
    "    final_attributes = []\n",
    "    final_attributes.append(attributes[index_of_class_attribute])\n",
    "    \n",
    "    for i, attribute in enumerate(attributes):\n",
    "        if i != index_of_class_attribute:\n",
    "            final_attributes.append(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Główne wywołanie algorytmu i rysowanie grafu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_network = TANAlgorithm(final_attributes, sample_data).find_net()\n",
    "\n",
    "graph = graphviz.Digraph('generated graph')        \n",
    "for node in bayesian_network:\n",
    "    if not node['parents']:\n",
    "        graph.node(node['name'] , label = node['name'])\n",
    "    else:\n",
    "        for parent in node['parents']:\n",
    "            graph.edge(parent['name'], node['name'])          \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Klasyfikacja przy dowolnych podanych warunkach\n",
    "<img src=\"img/classify.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class From(object):\n",
    "    def __init__(self, bayesian_network, test_data):\n",
    "        self.bayesian_network = bayesian_network\n",
    "        self.conditionals = []\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def given(self, name, value):\n",
    "        self.conditionals.append({\"name\": name, \"value\": value})\n",
    "        return self\n",
    "    \n",
    "    def classify(self, class_attribute_name):\n",
    "        final_result = []\n",
    "        for class_state in self.find_class_attribute_states(class_attribute_name):\n",
    "            result = 1\n",
    "            temp_conditionals = copy.deepcopy(self.conditionals)\n",
    "            temp_conditionals.append({\"name\": class_attribute_name, \"value\": class_state})\n",
    "            \n",
    "            for node in self.bayesian_network:\n",
    "                tuples = []\n",
    "                tuples.append((node[\"name\"], self.get_conditional_value(node['name'], temp_conditionals), True))\n",
    "                    \n",
    "                for parent in node['parents']:    \n",
    "                    tuples.append((parent['name'], self.get_conditional_value(parent['name'], temp_conditionals), False))\n",
    "                    \n",
    "                result *= self.compute_probability(tuples)\n",
    "            \n",
    "            final_result.append({\"state\": class_state, \"value\": result})  \n",
    "                \n",
    "        return self.normalize_probabilities_sum(final_result)\n",
    "    \n",
    "    def normalize_probabilities_sum(self, result_table):\n",
    "        probabilities_sum = self.compute_probabilities_sum(result_table)\n",
    "        for result in result_table:\n",
    "            result['value'] = (result['value'] / probabilities_sum) * 100.0\n",
    "        return result_table\n",
    "    \n",
    "    def compute_probabilities_sum(self, result_table):\n",
    "        probabilities_sum = 0\n",
    "        for result in result_table:\n",
    "            probabilities_sum += result['value']\n",
    "        return probabilities_sum\n",
    "            \n",
    "    def get_conditional_value(self, name, conditionals):\n",
    "        for conditional in conditionals:\n",
    "            if conditional[\"name\"] == name:\n",
    "                return conditional[\"value\"]\n",
    "        raise ValueError(\"There's no \" + name + \" conditional in conditionals\")\n",
    "    \n",
    "    def find_class_attribute_states(self, class_attribute_name):\n",
    "        for node in self.bayesian_network:\n",
    "            if (node['name'] == class_attribute_name):\n",
    "                return node['r']\n",
    "            \n",
    "        raise ValueError(class_attribute_name + \" -> No class attribute state error\")\n",
    "    \n",
    "    def compute_probability(self, tuples):\n",
    "        all_conditions_counter = self.count_occurences_of_fullfilled_conditions(tuples)\n",
    "        \n",
    "        if len(tuples) == 0: \n",
    "            return all_conditions_counter / len(self.test_data)\n",
    "\n",
    "        self.delete_parent_from_tuples(tuples)\n",
    "        \n",
    "        parent_conditions_counter = self.count_occurences_of_fullfilled_conditions(tuples)\n",
    "        \n",
    "        if all_conditions_counter == 0 or parent_conditions_counter == 0:\n",
    "            return 1 / self.count_number_of_states(tuples)\n",
    "\n",
    "        return all_conditions_counter / parent_conditions_counter\n",
    "    \n",
    "    def count_occurences_of_fullfilled_conditions(self, tuples):\n",
    "        counter = 0\n",
    "        for test_data_line in self.test_data:\n",
    "            if (self.does_test_line_fullfill_conditions(tuples, test_data_line)):\n",
    "                counter += 1\n",
    "        return counter\n",
    "    \n",
    "    def does_test_line_fullfill_conditions(self, tuples, test_data_line):\n",
    "        for condition_tuple in tuples:\n",
    "            if test_data_line[condition_tuple[0]] != condition_tuple[1]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def count_number_of_states(self, tuples):\n",
    "        result = 0\n",
    "        for single_tuple in tuples:\n",
    "            for node in self.bayesian_network:\n",
    "                if node['name'] == single_tuple[0]:\n",
    "                    result += len(node['r'])\n",
    "        return result\n",
    "    \n",
    "    def delete_parent_from_tuples(self, tuples):\n",
    "        for i, single_tuple in enumerate(tuples):\n",
    "            if single_tuple[2]:\n",
    "                del tuples[i]\n",
    "        return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'hot').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'hot').given('humidity', 'high').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'hot').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'mild').given('humidity', 'high').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'cool').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'sunny').given('temperature', 'mild').given('humidity', 'normal').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'mild').given('humidity', 'high').given('windy', 'TRUE').classify('play'))\n",
    "print(\"Should be yes\", From(bayesian_network, sample_data).given('outlook', 'overcast').given('temperature', 'hot').given('humidity', 'normal').given('windy', 'FALSE').classify('play'))\n",
    "print(\"Should be no\", From(bayesian_network, sample_data).given('outlook', 'rainy').given('temperature', 'mild').given('humidity', 'high').given('windy', 'TRUE').classify('play'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
